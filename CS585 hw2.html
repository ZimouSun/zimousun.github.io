
<!-- saved from url=(0081)https://www.cs.bu.edu/faculty/betke/cs585/restricted/cs585-homework-template.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title> CAS CS 585 - Spring 2021 Homework2 Programming Assignment  </title>
<style>
<!--
body{
font-family: 'Trebuchet MS', Verdana;
}
p{
font-family: 'Trebuchet MS', Times;
margin: 10px 10px 15px 20px;
}
h3{
margin: 5px;
}
h2{
margin: 10px;
}
h1{
margin: 10px 0px 0px 20px;
}
div.main-body{
align:center;
margin: 30px;
}
hr{
margin:20px 0px 20px 0px;
}
-->
</style>
</head>

<body data-new-gr-c-s-check-loaded="14.980.0" data-gr-ext-installed="">
<center>
<a href="http://www.bu.edu/"><img border="0" src="./CS585 Homework Template_ HW[x] Student Name [xxx]_files/bu-logo.gif" width="119" height="120"></a>
</center>

<h1>CAS CS 585 - Spring 2021 Homework2 Programming Assignment</h1>
<p> 
 CS 585 HW 2 <br>
 Zimou Sun <br>
 Yipei Su, Bowen Sun, Hao He. <br>
 Wednesday, February 16th 2021
</p>

<div class="main-body">
<hr>
<h2> Problem Definition </h2>
<p>
The goal of this assignment to develop an algorithm that is capable of detecting different hand shapes or gestures.  
To problems we need to solve are: how to extract only the hand region from the original image frames; 
how to evaluate the probability of one handshape or gesture among all possible candidates;
; how to set up a threshold for the detection algorithm; how to make the program responsive.
While developing the program, we assume the context/background is not too noisy and typically does not 
 contain objects that have colors looked like skin color. 
The result of this program illustrates that computer vision is capable of interpreting certain body language.
</p>

<hr>
<h2> Method and Implementation </h2>

<p>This program was implemented in Python 3 with supports from openCV and numpy libraries. 
It will read video frames through a webcam, and detects if the videos contain any of the four given kinds of hand shapes
and one hand gesture. There is a window, which will display the hand shape or gesture as soon as the algorithm recoginzed it.
</p>

<p>
Preprocessing Video Frame :<br>
The first stage is preprocessing video frames. For each frame, we apply skin detection and use the OpenCV library function "cv2.findContours" to help identify the hand region of the original frame image. In skin detection, we set up a threshold B>20 , G > 40, R >150, and assign (255,255,255) to the pixels passed. Then the next task will be calling "findContours" function to find a list of bounding boxes from the preprocessing frame. And we pick the bounding box that gives us the largest area to return.
</p>

<p>
Hand Shape Detection:
<br>
For hand shape Detection we have created a set of binary templates for 4 kinds of hand shapes and use template matching to identify valid hand shapes from the input. We first resize the template to the same dimensions of the hand image(from preprocessing), then we call the openCV "absdiff" function to calculate the absolute difference between the template and the hand image. We also create a flipped version of the template, to cover the hand shape in the other direction. The smaller the difference between the image and the template the more likely it is a match. Eventually, there is a max difference value and a bounding box size check to guard the validity of our detection.
</p>

<p>
Hand Movement Detection:
<br>
For hand movement "waving", we have two types of binary template, frame-to-frame differencing templates set and
motion energy templates set, and two correspondings (types of) the hand image. To detect, we calculate the normalized correlation coefficient
for each template-"hand image" pair and submit the maximum NCC score to final check. We set a threshold for waving's NCC score(0.5),
and a minimum size check for the hand image. Additionally, to speed up the computation, the mean and standard deviation of templates were precalculated. 

</p>


<hr>
<h2>Experiments</h2>
<p>
I performed on different thresholds for red and green channels.
</p>
<p>
 B G R values : 
 </P>
 <table>
  <tbody>
   <tr>
   <th> 20_40_95 </th>
   <th> 20_40_150 </th>
   <th>20_140_95</th>
   <th> 20_140_195 </th>

   </tr>

   <tr>
    
    <th><img style="display:block;" width="100%" src="20_40_95.jpg"> </th>
    <th><img style="display:block;" width="100%" src="20_40_150.jpg"> </th>
    <th><img style="display:block;" width="100%" src="20_140_95.jpg"> </th>
    <th><img style="display:block;" width="100%" src="20_140_195.jpg"> </th>
    
   </tr>
  </tbody>
 </table>
<p>
 Tuning the thresholds for red and green channels work well on reducing background noise, and leaving only skin regions.
 </p>

<hr>
<h2> Results</h2>
<p>
Eventually the program is able to detect four hand shapes:  ok ,  pistol, thumb down , thumb up. And also one gesture :waving.


</p>

<p>
<table>
  <tbody>
   <tr>
   <th> ok </th>
   <th> pistol </th>
   <th>thumb down</th>
   <th> thumb up </th>
   <th> waving 1 </th>
   <th> waving 2 </th>
   </tr>

   <tr>
    
    <th><img style="display:block;" width="100%" src="ok.jpg"> </th>
    <th><img style="display:block;" width="100%" src="pistol.jpg"> </th>
    <th><img style="display:block;" width="100%" src="thumb_down.jpg"> </th>
    <th><img style="display:block;" width="100%" src="thumb_up.jpg"> </th>
    <th><img style="display:block;" width="100%" src="waving1.jpg"> </th>
    <th><img style="display:block;" width="100%" src="waving2.jpg"> </th>
    
   </tr>
  </tbody>
 </table>
 And the Confusion matrix: 
 <img style="display:block;" width="100%" src="hw2_cm.jpg"> 
</p>



<hr>
<h2> Discussion </h2>

<p> 
Discuss your method and results:
</p><ul>
<li> The program requires user to manully tune the skin detection thresholds when used under different contexts. However, once the tunning is done, the algorithm is capable of 
 detect gesture and hand shapes, which it was designed to recognize. </li>
<li>In the developement process, we found that using normalized correlation correfficient to measure how likelihood of a positive detection is quite accurate. Althought we only
 use NCC for gesture detection, but it was confirmed to work just as well on hand shapes detection. So the application of NCC is general success. </li>
<li>There are many other measures like circularity , object orientation, centroid can be added to the likelihood calculate for each candidates. However, now we were not able to 
 implement all these image moments into the algorithm due to the fact doing that will slow down the computation and make the program no longer respondsive</li> 
</ul>
<p></p>

<hr>
<h2> Conclusions </h2>

<p>
This program shows that computer vision has the potential of understanding human body language. But itself is not intelligent enough. In the future, we may consider 
add a feature that will make thee skin detection setting get adapted to the enviroment automatically. Also by further optimizing the way we implement heavy computation part of the 
 algorithm, we may be able to add more measure to boost the precision of this program.
</p>


<hr>
<h2> Credits and Bibliography </h2>
<p>

CS585: Lecture 1/18/2021 - 2/11/2021
CS585: Lab2 ,Lab3 (2021 Spring) 

</p>

<p>
 Thanks to Yipei Su, Bowen Sun, Hao He.
</p>
<hr>
</div>





</body></html>
